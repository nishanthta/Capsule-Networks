{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CapsNetCIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nishanthta/Capsule-Networks/blob/master/CapsNetCIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "umnStqLbHRGM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "YjDNeDNzSGet",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Imports including CIFAR 10 (included in keras.datasets) and ImageDataGenerator provided by Keras for data augmentation"
      ]
    },
    {
      "metadata": {
        "id": "ZVoxEq1oG_y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa7d5a1d-685a-49e6-9b0d-4133e6544e50"
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "from keras import backend as K\n",
        "from keras.layers import Layer\n",
        "from keras import activations\n",
        "from keras import utils\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "s4nGRORBHqvb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Squash function, using $0.5$ instead of $1$ in the denominator to squash the capsules\n",
        "\n",
        "$squash(x) =||x|| / (0.5 + ||x||^2)$"
      ]
    },
    {
      "metadata": {
        "id": "6B304z_mHlZ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def squash(x, axis=-1):\n",
        "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True) + K.epsilon()\n",
        "    scale = K.sqrt(s_squared_norm) / (0.5 + s_squared_norm)\n",
        "    return scale * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FpN735KiTqVl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We define our own $softmax$ function as the one provided by Keras does not include the provision to specify axis "
      ]
    },
    {
      "metadata": {
        "id": "bb0jy4ZzIWZZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def softmax(x, axis=-1):\n",
        "    ex = K.exp(x - K.max(x, axis=axis, keepdims=True))\n",
        "    return ex / K.sum(ex, axis=axis, keepdims=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V9MIy49IT78F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Margin loss, implemented as described in Hinton's paper"
      ]
    },
    {
      "metadata": {
        "id": "H37EDyc2IZy0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def margin_loss(y_true, y_pred):\n",
        "    lamb, margin = 0.5, 0.1\n",
        "    return K.sum(y_true * K.square(K.relu(1 - margin - y_pred)) + lamb * (\n",
        "        1 - y_true) * K.square(K.relu(y_pred - margin)), axis=-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K8RKemvnULo8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Capsules, as implemented in https://github.com/bojone/Capsule/"
      ]
    },
    {
      "metadata": {
        "id": "0eXeNTh0If4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Capsule(Layer):\n",
        "    \"\"\"\n",
        "    There are two vesions of Capsule.\n",
        "    One is like dense layer (for the fixed-shape input),\n",
        "    and the other is like timedistributed dense (for various length input).\n",
        "    The input shape of Capsule must be (batch_size,\n",
        "                                        input_num_capsule,\n",
        "                                        input_dim_capsule\n",
        "                                       )\n",
        "    and the output shape is (batch_size,\n",
        "                             num_capsule,\n",
        "                             dim_capsule\n",
        "                            )\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_capsule,\n",
        "                 dim_capsule,\n",
        "                 routings=3,\n",
        "                 share_weights=True,\n",
        "                 activation='squash',\n",
        "                 **kwargs):\n",
        "        super(Capsule, self).__init__(**kwargs)\n",
        "        self.num_capsule = num_capsule\n",
        "        self.dim_capsule = dim_capsule\n",
        "        self.routings = routings\n",
        "        self.share_weights = share_weights\n",
        "        if activation == 'squash':\n",
        "            self.activation = squash\n",
        "        else:\n",
        "            self.activation = activations.get(activation)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        input_dim_capsule = input_shape[-1]\n",
        "        if self.share_weights:\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(1, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "        else:\n",
        "            input_num_capsule = input_shape[-2]\n",
        "            self.kernel = self.add_weight(\n",
        "                name='capsule_kernel',\n",
        "                shape=(input_num_capsule, input_dim_capsule,\n",
        "                       self.num_capsule * self.dim_capsule),\n",
        "                initializer='glorot_uniform',\n",
        "                trainable=True)\n",
        "\n",
        "    def call(self, inputs):\n",
        "        \"\"\"Following the routing algorithm from Hinton's paper,\n",
        "        but replace b = b + <u,v> with b = <u,v>.\n",
        "        This change can improve the feature representation of Capsule.\n",
        "        However, you can replace\n",
        "            b = K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        with\n",
        "            b += K.batch_dot(outputs, hat_inputs, [2, 3])\n",
        "        to realize a standard routing.\n",
        "        \"\"\"\n",
        "\n",
        "        if self.share_weights:\n",
        "            hat_inputs = K.conv1d(inputs, self.kernel)\n",
        "        else:\n",
        "            hat_inputs = K.local_conv1d(inputs, self.kernel, [1], [1])\n",
        "\n",
        "        batch_size = K.shape(inputs)[0]\n",
        "        input_num_capsule = K.shape(inputs)[1]\n",
        "        hat_inputs = K.reshape(hat_inputs,\n",
        "                               (batch_size, input_num_capsule,\n",
        "                                self.num_capsule, self.dim_capsule))\n",
        "        hat_inputs = K.permute_dimensions(hat_inputs, (0, 2, 1, 3))\n",
        "\n",
        "        b = K.zeros_like(hat_inputs[:, :, :, 0])\n",
        "        for i in range(self.routings):\n",
        "            c = softmax(b, 1)\n",
        "            o = self.activation(K.batch_dot(c, hat_inputs, [2, 2]))\n",
        "            if i < self.routings - 1:\n",
        "                b = K.batch_dot(o, hat_inputs, [2, 3])\n",
        "                if K.backend() == 'theano':\n",
        "                    o = K.sum(o, axis=1)\n",
        "\n",
        "        return o\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return (None, self.num_capsule, self.dim_capsule)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1QyS71KyIlsG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "161c1fa0-8dde-40b6-b470-a7738a044564"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 36s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lHOSsC-XIsJJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "y_train = utils.to_categorical(y_train, num_classes)\n",
        "y_test = utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GJi74-OrJMAF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_image = Input(shape=(None, None, 3))\n",
        "x = Conv2D(64, (3, 3), activation='relu')(input_image)\n",
        "x = Conv2D(64, (3, 3), activation='relu')(x)\n",
        "x = AveragePooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu')(x)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IUgprrFSJOm1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x = Reshape((-1, 128))(x)\n",
        "capsule = Capsule(10, 16, 3, True)(x)\n",
        "output = Lambda(lambda z: K.sqrt(K.sum(K.square(z), 2)))(capsule)\n",
        "model = Model(inputs=input_image, outputs=output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8_O_wbcOJSFP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "5961589e-6c4a-4c59-f4e3-7f579c11abc3"
      },
      "cell_type": "code",
      "source": [
        "model.compile(loss=margin_loss, optimizer='adam', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, None, None, 64)    1792      \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n",
            "_________________________________________________________________\n",
            "average_pooling2d_1 (Average (None, None, None, 64)    0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, None, 128)         0         \n",
            "_________________________________________________________________\n",
            "capsule_1 (Capsule)          (None, 10, 16)            20480     \n",
            "_________________________________________________________________\n",
            "lambda_1 (Lambda)            (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 280,640\n",
            "Trainable params: 280,640\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j8I6WRPDJWXR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3451
        },
        "outputId": "edb1d00f-8abb-4fa9-f2e9-3cf0ace96d94"
      },
      "cell_type": "code",
      "source": [
        "data_augmentation = False\n",
        "\n",
        "if not data_augmentation:\n",
        "    print('Not using data augmentation.')\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=epochs,\n",
        "        validation_data=(x_test, y_test),\n",
        "        shuffle=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Not using data augmentation.\n",
            "Train on 50000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "50000/50000 [==============================] - 22s 437us/step - loss: 0.4246 - acc: 0.3495 - val_loss: 0.3587 - val_acc: 0.4829\n",
            "Epoch 2/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.3306 - acc: 0.5260 - val_loss: 0.3002 - val_acc: 0.5774\n",
            "Epoch 3/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.2808 - acc: 0.6125 - val_loss: 0.2716 - val_acc: 0.6246\n",
            "Epoch 4/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.2505 - acc: 0.6649 - val_loss: 0.2390 - val_acc: 0.6802\n",
            "Epoch 5/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.2255 - acc: 0.7050 - val_loss: 0.2366 - val_acc: 0.6910\n",
            "Epoch 6/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.2063 - acc: 0.7334 - val_loss: 0.2083 - val_acc: 0.7309\n",
            "Epoch 7/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.1923 - acc: 0.7566 - val_loss: 0.2098 - val_acc: 0.7202\n",
            "Epoch 8/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1818 - acc: 0.7720 - val_loss: 0.2010 - val_acc: 0.7400\n",
            "Epoch 9/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1708 - acc: 0.7910 - val_loss: 0.1870 - val_acc: 0.7638\n",
            "Epoch 10/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1621 - acc: 0.8046 - val_loss: 0.1866 - val_acc: 0.7617\n",
            "Epoch 11/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.1518 - acc: 0.8204 - val_loss: 0.1870 - val_acc: 0.7643\n",
            "Epoch 12/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.1447 - acc: 0.8311 - val_loss: 0.1861 - val_acc: 0.7574\n",
            "Epoch 13/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1371 - acc: 0.8453 - val_loss: 0.1766 - val_acc: 0.7725\n",
            "Epoch 14/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.1280 - acc: 0.8592 - val_loss: 0.1664 - val_acc: 0.7948\n",
            "Epoch 15/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.1217 - acc: 0.8694 - val_loss: 0.1859 - val_acc: 0.7670\n",
            "Epoch 16/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.1148 - acc: 0.8812 - val_loss: 0.1738 - val_acc: 0.7916\n",
            "Epoch 17/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.1087 - acc: 0.8916 - val_loss: 0.1702 - val_acc: 0.7937\n",
            "Epoch 18/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.1003 - acc: 0.9048 - val_loss: 0.1737 - val_acc: 0.7883\n",
            "Epoch 19/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0935 - acc: 0.9163 - val_loss: 0.1707 - val_acc: 0.7956\n",
            "Epoch 20/100\n",
            "50000/50000 [==============================] - 17s 340us/step - loss: 0.0872 - acc: 0.9257 - val_loss: 0.1735 - val_acc: 0.7907\n",
            "Epoch 21/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0824 - acc: 0.9331 - val_loss: 0.1737 - val_acc: 0.7874\n",
            "Epoch 22/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0751 - acc: 0.9454 - val_loss: 0.1705 - val_acc: 0.7966\n",
            "Epoch 23/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0697 - acc: 0.9527 - val_loss: 0.1784 - val_acc: 0.7933\n",
            "Epoch 24/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0656 - acc: 0.9578 - val_loss: 0.1824 - val_acc: 0.7861\n",
            "Epoch 25/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0608 - acc: 0.9641 - val_loss: 0.1855 - val_acc: 0.7788\n",
            "Epoch 26/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0564 - acc: 0.9699 - val_loss: 0.1805 - val_acc: 0.7876\n",
            "Epoch 27/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0520 - acc: 0.9747 - val_loss: 0.1836 - val_acc: 0.7860\n",
            "Epoch 28/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0460 - acc: 0.9808 - val_loss: 0.1931 - val_acc: 0.7780\n",
            "Epoch 29/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0444 - acc: 0.9821 - val_loss: 0.1903 - val_acc: 0.7786\n",
            "Epoch 30/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0414 - acc: 0.9853 - val_loss: 0.1920 - val_acc: 0.7803\n",
            "Epoch 31/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0390 - acc: 0.9865 - val_loss: 0.1935 - val_acc: 0.7781\n",
            "Epoch 32/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0354 - acc: 0.9898 - val_loss: 0.1983 - val_acc: 0.7801\n",
            "Epoch 33/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0332 - acc: 0.9913 - val_loss: 0.2029 - val_acc: 0.7704\n",
            "Epoch 34/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0318 - acc: 0.9915 - val_loss: 0.2066 - val_acc: 0.7660\n",
            "Epoch 35/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0294 - acc: 0.9932 - val_loss: 0.2037 - val_acc: 0.7735\n",
            "Epoch 36/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0267 - acc: 0.9944 - val_loss: 0.2002 - val_acc: 0.7755\n",
            "Epoch 37/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0260 - acc: 0.9948 - val_loss: 0.2040 - val_acc: 0.7697\n",
            "Epoch 38/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0234 - acc: 0.9961 - val_loss: 0.2145 - val_acc: 0.7604\n",
            "Epoch 39/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0218 - acc: 0.9968 - val_loss: 0.2073 - val_acc: 0.7692\n",
            "Epoch 40/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0205 - acc: 0.9965 - val_loss: 0.2117 - val_acc: 0.7654\n",
            "Epoch 41/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0206 - acc: 0.9971 - val_loss: 0.2135 - val_acc: 0.7622\n",
            "Epoch 42/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0210 - acc: 0.9968 - val_loss: 0.2149 - val_acc: 0.7627\n",
            "Epoch 43/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0195 - acc: 0.9974 - val_loss: 0.2160 - val_acc: 0.7613\n",
            "Epoch 44/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0183 - acc: 0.9976 - val_loss: 0.2169 - val_acc: 0.7583\n",
            "Epoch 45/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0167 - acc: 0.9980 - val_loss: 0.2196 - val_acc: 0.7589\n",
            "Epoch 46/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0160 - acc: 0.9981 - val_loss: 0.2157 - val_acc: 0.7594\n",
            "Epoch 47/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0160 - acc: 0.9981 - val_loss: 0.2215 - val_acc: 0.7585\n",
            "Epoch 48/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0138 - acc: 0.9985 - val_loss: 0.2208 - val_acc: 0.7567\n",
            "Epoch 49/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0140 - acc: 0.9984 - val_loss: 0.2233 - val_acc: 0.7563\n",
            "Epoch 50/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0138 - acc: 0.9985 - val_loss: 0.2229 - val_acc: 0.7547\n",
            "Epoch 51/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0170 - acc: 0.9978 - val_loss: 0.2285 - val_acc: 0.7489\n",
            "Epoch 52/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0149 - acc: 0.9983 - val_loss: 0.2251 - val_acc: 0.7534\n",
            "Epoch 53/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0117 - acc: 0.9989 - val_loss: 0.2264 - val_acc: 0.7531\n",
            "Epoch 54/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0109 - acc: 0.9991 - val_loss: 0.2268 - val_acc: 0.7540\n",
            "Epoch 55/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0118 - acc: 0.9988 - val_loss: 0.2332 - val_acc: 0.7484\n",
            "Epoch 56/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0130 - acc: 0.9985 - val_loss: 0.2284 - val_acc: 0.7527\n",
            "Epoch 57/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0130 - acc: 0.9986 - val_loss: 0.2289 - val_acc: 0.7512\n",
            "Epoch 58/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0117 - acc: 0.9990 - val_loss: 0.2282 - val_acc: 0.7512\n",
            "Epoch 59/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0098 - acc: 0.9992 - val_loss: 0.2325 - val_acc: 0.7446\n",
            "Epoch 60/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0119 - acc: 0.9987 - val_loss: 0.2393 - val_acc: 0.7419\n",
            "Epoch 61/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0131 - acc: 0.9987 - val_loss: 0.2336 - val_acc: 0.7460\n",
            "Epoch 62/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0093 - acc: 0.9991 - val_loss: 0.2298 - val_acc: 0.7463\n",
            "Epoch 63/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0079 - acc: 0.9993 - val_loss: 0.2331 - val_acc: 0.7447\n",
            "Epoch 64/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0119 - acc: 0.9989 - val_loss: 0.2386 - val_acc: 0.7413\n",
            "Epoch 65/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0095 - acc: 0.9991 - val_loss: 0.2349 - val_acc: 0.7467\n",
            "Epoch 66/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0101 - acc: 0.9989 - val_loss: 0.2388 - val_acc: 0.7405\n",
            "Epoch 67/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0087 - acc: 0.9992 - val_loss: 0.2346 - val_acc: 0.7490\n",
            "Epoch 68/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0078 - acc: 0.9994 - val_loss: 0.2436 - val_acc: 0.7376\n",
            "Epoch 69/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0127 - acc: 0.9984 - val_loss: 0.2402 - val_acc: 0.7363\n",
            "Epoch 70/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0093 - acc: 0.9992 - val_loss: 0.2416 - val_acc: 0.7368\n",
            "Epoch 71/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0058 - acc: 0.9995 - val_loss: 0.2420 - val_acc: 0.7357\n",
            "Epoch 72/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0086 - acc: 0.9991 - val_loss: 0.2424 - val_acc: 0.7394\n",
            "Epoch 73/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0116 - acc: 0.9987 - val_loss: 0.2443 - val_acc: 0.7402\n",
            "Epoch 74/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0092 - acc: 0.9991 - val_loss: 0.2438 - val_acc: 0.7349\n",
            "Epoch 75/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0072 - acc: 0.9994 - val_loss: 0.2415 - val_acc: 0.7388\n",
            "Epoch 76/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0069 - acc: 0.9994 - val_loss: 0.2421 - val_acc: 0.7375\n",
            "Epoch 77/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0090 - acc: 0.9990 - val_loss: 0.2520 - val_acc: 0.7296\n",
            "Epoch 78/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0108 - acc: 0.9988 - val_loss: 0.2411 - val_acc: 0.7372\n",
            "Epoch 79/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0069 - acc: 0.9996 - val_loss: 0.2435 - val_acc: 0.7406\n",
            "Epoch 80/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0048 - acc: 0.9996 - val_loss: 0.2440 - val_acc: 0.7369\n",
            "Epoch 81/100\n",
            "50000/50000 [==============================] - 17s 340us/step - loss: 0.0063 - acc: 0.9994 - val_loss: 0.2521 - val_acc: 0.7296\n",
            "Epoch 82/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0132 - acc: 0.9982 - val_loss: 0.2530 - val_acc: 0.7307\n",
            "Epoch 83/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0067 - acc: 0.9995 - val_loss: 0.2448 - val_acc: 0.7393\n",
            "Epoch 84/100\n",
            "50000/50000 [==============================] - 17s 336us/step - loss: 0.0046 - acc: 0.9997 - val_loss: 0.2478 - val_acc: 0.7342\n",
            "Epoch 85/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0070 - acc: 0.9992 - val_loss: 0.2501 - val_acc: 0.7283\n",
            "Epoch 86/100\n",
            "50000/50000 [==============================] - 17s 337us/step - loss: 0.0106 - acc: 0.9988 - val_loss: 0.2460 - val_acc: 0.7364\n",
            "Epoch 87/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0072 - acc: 0.9994 - val_loss: 0.2471 - val_acc: 0.7354\n",
            "Epoch 88/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0032 - acc: 0.9997 - val_loss: 0.2455 - val_acc: 0.7417\n",
            "Epoch 89/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0023 - acc: 0.9998 - val_loss: 0.2429 - val_acc: 0.7394\n",
            "Epoch 90/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0045 - acc: 0.9993 - val_loss: 0.2571 - val_acc: 0.7257\n",
            "Epoch 91/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0228 - acc: 0.9934 - val_loss: 0.2451 - val_acc: 0.7365\n",
            "Epoch 92/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0066 - acc: 0.9996 - val_loss: 0.2434 - val_acc: 0.7380\n",
            "Epoch 93/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0027 - acc: 0.9998 - val_loss: 0.2426 - val_acc: 0.7395\n",
            "Epoch 94/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0016 - acc: 0.9998 - val_loss: 0.2417 - val_acc: 0.7393\n",
            "Epoch 95/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.2439 - val_acc: 0.7389\n",
            "Epoch 96/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0011 - acc: 0.9998 - val_loss: 0.2452 - val_acc: 0.7391\n",
            "Epoch 97/100\n",
            "50000/50000 [==============================] - 17s 341us/step - loss: 0.0234 - acc: 0.9903 - val_loss: 0.2512 - val_acc: 0.7321\n",
            "Epoch 98/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0119 - acc: 0.9983 - val_loss: 0.2454 - val_acc: 0.7362\n",
            "Epoch 99/100\n",
            "50000/50000 [==============================] - 17s 338us/step - loss: 0.0036 - acc: 0.9998 - val_loss: 0.2451 - val_acc: 0.7366\n",
            "Epoch 100/100\n",
            "50000/50000 [==============================] - 17s 339us/step - loss: 0.0015 - acc: 0.9998 - val_loss: 0.2429 - val_acc: 0.7377\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}